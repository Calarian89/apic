{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, explode, lit\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ServerInfo:\n",
    "    name: str\n",
    "    base_url: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class JsonDataLoader:\n",
    "    spark: SparkSession\n",
    "    dbutils: object\n",
    "    read_dirs: list[str]\n",
    "    target: str\n",
    "\n",
    "    def __init__(self, spark, dbutils, read_dirs, target):\n",
    "        self.spark = spark\n",
    "        self.dbutils = dbutils\n",
    "        self.read_dirs = read_dirs\n",
    "        self.target = target\n",
    "\n",
    "    def read_json(self, file_path: str) -> DataFrame:\n",
    "        return self.spark.read.json(file_path, multiLine=True)\n",
    "\n",
    "    def normalize_schema(self, df: DataFrame) -> DataFrame:\n",
    "        # Ensure the DataFrame has all the required columns with the same schema\n",
    "        columns = [\n",
    "            \"address\",\n",
    "            \"dn\",\n",
    "            \"fabricSt\",\n",
    "            \"id\",\n",
    "            \"lastStateModTs\",\n",
    "            \"modTs\",\n",
    "            \"model\",\n",
    "            \"name\",\n",
    "            \"role\",\n",
    "            \"serial\",\n",
    "            \"vendor\",\n",
    "            \"version\",\n",
    "            \"device_type\",\n",
    "            \"descr\",\n",
    "            \"hwVer\",\n",
    "            \"macB\",\n",
    "            \"rdSt\",\n",
    "        ]\n",
    "        for column in columns:\n",
    "            if column not in df.columns:\n",
    "                df = df.withColumn(column, lit(None).cast(StringType()))\n",
    "        return df.select(columns)\n",
    "\n",
    "    def map_columns(self, df: DataFrame) -> DataFrame:\n",
    "        # Map columns to ensure consistency\n",
    "        column_mapping = {\n",
    "            \"ser\": \"serial\",\n",
    "            \"address\": \"address\",\n",
    "            \"dn\": \"dn\",\n",
    "            \"fabricSt\": \"fabricSt\",\n",
    "            \"id\": \"id\",\n",
    "            \"lastStateModTs\": \"lastStateModTs\",\n",
    "            \"modTs\": \"modTs\",\n",
    "            \"model\": \"model\",\n",
    "            \"name\": \"name\",\n",
    "            \"role\": \"role\",\n",
    "            \"serial\": \"serial\",\n",
    "            \"vendor\": \"vendor\",\n",
    "            \"version\": \"version\",\n",
    "            \"device_type\": \"device_type\",\n",
    "            \"descr\": \"descr\",\n",
    "            \"hwVer\": \"hwVer\",\n",
    "            \"macB\": \"macB\",\n",
    "            \"rdSt\": \"rdSt\",\n",
    "        }\n",
    "        for old_col, new_col in column_mapping.items():\n",
    "            if old_col in df.columns:\n",
    "                df = df.withColumnRenamed(old_col, new_col)\n",
    "        return df\n",
    "\n",
    "    def extract_chassis_attributes(self, df: DataFrame, path: str) -> DataFrame:\n",
    "        exploded_df = df.withColumn(\"element\", explode(col(path)))\n",
    "        attributes_df = exploded_df.select(col(\"element.fabricNode.attributes.*\"))\n",
    "        attributes_df = attributes_df.withColumn(\"device_type\", lit(\"chassis\"))\n",
    "        return self.map_columns(attributes_df)\n",
    "\n",
    "    def extract_linecard_attributes(self, df: DataFrame, path: str) -> DataFrame:\n",
    "        exploded_df = df.withColumn(\"leaf_element\", explode(col(path)))\n",
    "        exploded_df = exploded_df.withColumn(\n",
    "            \"lc_element\", explode(col(\"leaf_element.linecard.imdata\"))\n",
    "        )\n",
    "        attributes_df = exploded_df.select(col(\"lc_element.eqptLC.attributes.*\"))\n",
    "        attributes_df = attributes_df.withColumn(\"device_type\", lit(\"linecard\"))\n",
    "        return self.map_columns(attributes_df)\n",
    "\n",
    "    def process_json_file(self, file_path: str):\n",
    "        df = self.read_json(file_path)\n",
    "        environments = [\"lab\", \"prod\"]\n",
    "        final_df = None\n",
    "\n",
    "        for env in environments:\n",
    "            for pod in [\"1\", \"2\"]:\n",
    "                pod_path = f\"environments.{env}.pods.{pod}.nodes.imdata\"\n",
    "                try:\n",
    "                    exploded_df = self.extract_chassis_attributes(df, pod_path)\n",
    "                    exploded_df = self.normalize_schema(exploded_df)\n",
    "                    final_df = (\n",
    "                        exploded_df\n",
    "                        if final_df is None\n",
    "                        else final_df.unionByName(exploded_df)\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing path {pod_path}: {e}\")\n",
    "\n",
    "        for env in environments:\n",
    "            for pod in [\"1\", \"2\"]:\n",
    "                leaf_nodes_path = f\"environments.{env}.pods.{pod}.leaf_nodes_data\"\n",
    "                try:\n",
    "                    leaf_exploded_df = self.extract_linecard_attributes(\n",
    "                        df, leaf_nodes_path\n",
    "                    )\n",
    "                    leaf_exploded_df = self.normalize_schema(leaf_exploded_df)\n",
    "                    final_df = (\n",
    "                        leaf_exploded_df\n",
    "                        if final_df is None\n",
    "                        else final_df.unionByName(leaf_exploded_df)\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing path {leaf_nodes_path}: {e}\")\n",
    "\n",
    "        if final_df:\n",
    "            final_df.select(\n",
    "                col(\"address\").alias(\"Address\"),\n",
    "                col(\"dn\").alias(\"DN\"),\n",
    "                col(\"fabricSt\").alias(\"FabricSt\"),\n",
    "                col(\"id\").alias(\"ID\"),\n",
    "                col(\"lastStateModTs\").alias(\"LastStateModTs\"),\n",
    "                col(\"modTs\").alias(\"ModTs\"),\n",
    "                col(\"model\").alias(\"Model\"),\n",
    "                col(\"name\").alias(\"Name\"),\n",
    "                col(\"role\").alias(\"Role\"),\n",
    "                col(\"serial\").alias(\"Serial\"),\n",
    "                col(\"vendor\").alias(\"Vendor\"),\n",
    "                col(\"version\").alias(\"Version\"),\n",
    "                col(\"device_type\"),\n",
    "                col(\"descr\").alias(\"Descr\"),\n",
    "                col(\"hwVer\").alias(\"HwVer\"),\n",
    "                col(\"macB\").alias(\"MacB\"),\n",
    "                col(\"rdSt\").alias(\"RdSt\"),\n",
    "            ).write.mode(\"overwrite\").parquet(self.target)\n",
    "\n",
    "        self.dbutils.fs.mv(file_path, file_path.replace(\"/unprocessed\", \"/processed\"))\n",
    "\n",
    "    def load_files(self) -> None:\n",
    "        for read_dir in self.read_dirs:\n",
    "            files_raw = self.dbutils.fs.ls(f\"{read_dir}/unprocessed\")\n",
    "            files = [file.path for file in files_raw if file.name.endswith(\".json\")]\n",
    "            for file_path in files:\n",
    "                self.process_json_file(file_path)\n",
    "\n",
    "\n",
    "# Define common attribute structure\n",
    "attributes_schema = StructType(\n",
    "    [\n",
    "        StructField(\"address\", StringType(), True),\n",
    "        StructField(\"dn\", StringType(), True),\n",
    "        StructField(\"fabricSt\", StringType(), True),\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"lastStateModTs\", StringType(), True),\n",
    "        StructField(\"modTs\", StringType(), True),\n",
    "        StructField(\"model\", StringType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"role\", StringType(), True),\n",
    "        StructField(\"serial\", StringType(), True),\n",
    "        StructField(\"vendor\", StringType(), True),\n",
    "        StructField(\"version\", StringType(), True),\n",
    "        StructField(\"descr\", StringType(), True),\n",
    "        StructField(\"hwVer\", StringType(), True),\n",
    "        StructField(\"macB\", StringType(), True),\n",
    "        StructField(\"rdSt\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the fabricNode schema\n",
    "fabric_node_schema = StructType(\n",
    "    [\n",
    "        StructField(\n",
    "            \"fabricNode\", StructType([StructField(\"attributes\", attributes_schema)])\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the nodes schema\n",
    "nodes_schema = StructType(\n",
    "    [\n",
    "        StructField(\"totalCount\", StringType(), True),\n",
    "        StructField(\"imdata\", ArrayType(fabric_node_schema)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the leaf_nodes_data schema\n",
    "leaf_nodes_data_schema = StructType(\n",
    "    [\n",
    "        StructField(\"leaf_dn\", StringType(), True),\n",
    "        StructField(\"role\", StringType(), True),\n",
    "        StructField(\n",
    "            \"linecard\",\n",
    "            StructType(\n",
    "                [\n",
    "                    StructField(\"totalCount\", StringType(), True),\n",
    "                    StructField(\n",
    "                        \"imdata\",\n",
    "                        ArrayType(\n",
    "                            StructType(\n",
    "                                [\n",
    "                                    StructField(\n",
    "                                        \"eqptLC\",\n",
    "                                        StructType(\n",
    "                                            [\n",
    "                                                StructField(\n",
    "                                                    \"attributes\", attributes_schema\n",
    "                                                )\n",
    "                                            ]\n",
    "                                        ),\n",
    "                                    )\n",
    "                                ]\n",
    "                            )\n",
    "                        ),\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to create the pods schema\n",
    "def create_pods_schema() -> StructType:\n",
    "    return StructType(\n",
    "        [\n",
    "            StructField(\"1\", nodes_schema),\n",
    "            StructField(\"2\", nodes_schema),\n",
    "            StructField(\"leaf_nodes_data\", ArrayType(leaf_nodes_data_schema)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# Define the main schema for environments\n",
    "apic_schemas = StructType(\n",
    "    [\n",
    "        StructField(\n",
    "            \"environments\",\n",
    "            StructType(\n",
    "                [\n",
    "                    StructField(\n",
    "                        \"lab\", StructType([StructField(\"pods\", create_pods_schema())])\n",
    "                    ),\n",
    "                    StructField(\n",
    "                        \"prod\", StructType([StructField(\"pods\", create_pods_schema())])\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and use the JsonDataLoader\n",
    "json_data_loader = JsonDataLoader(\n",
    "    spark,\n",
    "    dbutils,\n",
    "    [\"/mnt/edl/raw/iit_apic_raw\"],\n",
    "    \"/mnt/edl/raw/iit_apic_raw/apic_data.parquet\",\n",
    ")\n",
    "json_data_loader.load_files()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
